{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the quality of a model against known data\n",
    "One of the challenges with Generative AI is measuring how effectively a model's output, especially at scale. Due to the stocastic nature of Generative AI, the output can vary from one call to another. Even if directionally the output is the same, you can't do a string comparison of the output, due to the variation in responses.\n",
    "\n",
    "However, there are some things you can do to score the simularity of two responses. \n",
    "\n",
    "### Using GenAI\n",
    "You can ask a model fo compare two responses.\n",
    "\n",
    "### Embeddings\n",
    "One way to compare the output would be to compare the embeddings vector between two responses. \n",
    "\n",
    "## Prerequisites\n",
    "* **Claude** enabled for your AWS Account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock(https://bedrock.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(os.environ.get('BEDROCK_ASSUME_ROLE', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "inference_modifier = {'max_tokens_to_sample':4096, \n",
    "                      \"temperature\":0.5,\n",
    "                      \"top_k\":250,\n",
    "                      \"top_p\":1,\n",
    "                      \"stop_sequences\": [\"\\n\\nHuman\"]\n",
    "                     }\n",
    "\n",
    "textgen_llm = Bedrock(model_id = \"anthropic.claude-v2\",\n",
    "                    client = boto3_bedrock, \n",
    "                    model_kwargs = inference_modifier \n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Comparison\n",
    "\n",
    "The notebook will create a summary from an example document, in this case, the Amazon 2022 letter to shareholders. The document is available in [example.py](example.py).\n",
    "\n",
    "It will be run through Claude Instant and Amazon Titan, and the resulting summary will be stored for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline_summary = \"\"\"\n",
    "Amazon continues to face challenges but is optimistic about the future. The company has made cost\n",
    "cuts and efficiency improvements in fulfillment and logistics networks to lower costs and speed up\n",
    "delivery times. AWS is facing short-term headwinds but has a strong customer base and continues to\n",
    "innovate with new products and technologies. Other businesses like Advertising, Amazon Business, and\n",
    "Buy with Prime continue to see strong growth. The company is also investing in new areas like\n",
    "grocery, healthcare, satellite internet access, and artificial intelligence which could provide\n",
    "large opportunities in the future. Although Amazon currently has a small share of the overall retail\n",
    "and IT markets, as more retail shifts online and to the cloud, the company believes it is well\n",
    "positioned for significant growth ahead.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate summaries\n",
    "There are four summaries provided.\n",
    "\n",
    "The first was created by Amazon Titan, the second is a completely unrelated article on Honus Wagner, and\n",
    "major leageu baseball player from the turn of the 20th century. The third is a summary of the 2017 letter to shareholders, and the final example is a summary by AI21 labs Jurassic Mid foundation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "candidates = [\n",
    "{\n",
    "    \"note\": \"Unrelated Article on Honus Wagner\",\n",
    "    \"text\": \"\"\"\n",
    "Johannes Peter \"Honus\" Wagner, sometimes referred to as Hans Wagner, was an American baseball shortstop\n",
    "who played 21 seasons in Major League Baseball from 1897 to 1917, almost entirely for the Pittsburgh Pirates.\n",
    "Wagner won his eighth (and final) batting title in 1911, a National League record that remains unbroken\n",
    "to this day, and matched only once, in 1997, by Tony Gwynn. He also led the league in slugging six times\n",
    "and stolen bases five times. Wagner was nicknamed \"the Flying Dutchman\" due to his superb speed and German\n",
    "heritage. This nickname was a nod to the popular folk-tale made into a famous opera by the German composer\n",
    "Richard Wagner. In 1936, the Baseball Hall of Fame inducted Wagner as one of the first five members.\n",
    "He received the second-highest vote total, behind Ty Cobb's 222 and tied with Babe Ruth at 215.\n",
    "\"\"\"\n",
    "},\n",
    "{\n",
    "    \"note\": \"Anthropic Claude on 2017 Letter\",\n",
    "    \"text\": \"\"\"In his 2017 letter to Amazon shareholders, Jeff Bezos emphasizes the importance \n",
    "of maintaining a \"Day 1\" mentality even as Amazon grows into a large company. He says customer obsession, \n",
    "resisting proxies, embracing external trends, and high-velocity decision making are essential to fending \n",
    "off \"Day 2\" stagnation and irrelevance. Bezos argues that obsessive customer focus drives innovation, that \n",
    "proxies like surveys can mislead, that trends like AI must be quickly embraced, and that quality high-speed \n",
    "decisions maintain energy and dynamism. He shares examples from Amazon like Alexa and Amazon Go to \n",
    "illustrate these points. Bezos stresses that large organizations must move with the spirit of a startup \n",
    "to delight customers and remain vital.\n",
    "\"\"\"\n",
    "},\n",
    "{\n",
    "    \"note\": \"AI21 Labs\",\n",
    "    \"text\": \"\"\"\n",
    "While Amazon has faced a challenging macroeconomic challenges in 2022, it has also been a year of growth\n",
    "and innovation, it has also seen a number of successes. The company continue to grow, innovated, improved \n",
    "its customer experiences, and made important adjustments to its investment strategies. The company has been\n",
    "focusing on long-term investment opportunities, and is constantly investing in long-term opportunities, \n",
    "and plans to lower costs, even as it faces short-term challenges.\n",
    "\"\"\"\n",
    "},\n",
    "{\n",
    "    \"note\": \"Amazon Titan\",\n",
    "    \"text\": \"\"\"\n",
    "Despite shutting down some businesses and making changes to others, Jassy remains confident in\n",
    "Amazon's future prospects. He highlights the company's ongoing efforts to improve fulfillment costs,\n",
    "speed up delivery, and expand its retail business. Jassy also discusses Amazon's investments in\n",
    "advertising, machine learning, and new business areas such as healthcare and satellite internet. He\n",
    "emphasizes the company's long-term vision and commitment to innovation.\n",
    "\"\"\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The comparison\n",
    "Now that both summaries have been completed, let's use the Claude v2 model to compare the two and decide which is better.\n",
    "\n",
    "The prompt below provides the entire document text, then both of the summaries. It then asks the foundation model which is more accurate and concise. If you value other dimensions of the summary more, you can include that in the prompt. Lastly, it gives a specific format to the output as an example, thus making it easier to parse.\n",
    "\n",
    "Notice how it includes the reasoning in the result. This tends to drive better results, as the model must justify its decision. Feel free to modify the code to ask for just a Yes/No response to which one is better. The results can be more random in that case.\n",
    "\n",
    "Lastly, run the comparison several times. The answer may change. Is the model hallucinating why one is better than the other? Can more details be added to the prompt to reduce this effect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compareText(text1, text2):\n",
    "    # Create a prompt template that has multiple input variables\n",
    "    multi_var_prompt2 = PromptTemplate(\n",
    "        input_variables=[\"text1\",\"text2\"],\n",
    "        template=\"\"\"Human: You are comparing 2 documents. On a scale of 1 to 100, how similar are the documents\n",
    "\n",
    "    <text1>{text1}</text1>\n",
    "    <text2>{text2}</text2>\n",
    "\n",
    "   Provide the response in JSON format with the similarity score in the score element and explain the justification in the reason element:\n",
    "    {{\n",
    "      \"score\": 100,\n",
    "      \"reason\": \"The justification for the selection\"\n",
    "    }}\n",
    "\n",
    "    Only respond with the json format above.\n",
    "\n",
    "    Assistant: \n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    prompt = multi_var_prompt2.format(text1=text1, text2=text2)\n",
    "\n",
    "\n",
    "    response = textgen_llm(prompt)\n",
    "\n",
    "    #target_code = response[response.index('\\n')+1:]\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrelated Article on Honus Wagner\n",
      " {\n",
      "  \"score\": 5, \n",
      "  \"reason\": \"The two texts are on completely different topics and do not share any similar words or ideas. The first text is about Amazon's business outlook and strategy. The second text is a biography of baseball player Honus Wagner. There is very little semantic or lexical overlap between these texts, indicating low similarity.\"\n",
      "}\n",
      "Anthropic Claude on 2017 Letter\n",
      " {\n",
      "  \"score\": 65, \n",
      "  \"reason\": \"While the two texts are not identical, they cover similar themes and concepts related to Amazon's business strategy, growth opportunities, and maintaining a startup mentality. Both discuss Amazon's efforts to innovate and delight customers across different business segments, as well as the importance of embracing new technologies and trends. There is significant topical overlap between the two texts, though they provide complementary perspectives and details. A similarity score of 65 reflects the strong topical relevance between the passages, but allows room for their differences in specifics and framing.\"\n",
      "}\n",
      "AI21 Labs\n",
      " {\n",
      "  \"score\": 90, \n",
      "  \"reason\": \"The two texts are very similar in content and themes. They both discuss Amazon facing challenges but remaining optimistic, making improvements in fulfillment/logistics to cut costs and speed up delivery, AWS facing short-term headwinds but having a strong customer base, continuing to invest and innovate in new areas for future growth opportunities. The main differences are minor details and wording choices.\"\n",
      "}\n",
      "Amazon Titan\n",
      " {\n",
      "  \"score\": 95, \n",
      "  \"reason\": \"The two documents discuss very similar topics and themes related to Amazon's business outlook and future plans. They both mention cost cuts, efficiency improvements, growth of AWS, Advertising, Amazon Business, grocery, healthcare, satellite internet, AI/ML, and long-term investments. The documents have extensive overlap in content and messaging, indicating a high degree of similarity.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for candidate in candidates:\n",
    "    print(candidate['note'])\n",
    "    print(compareText(baseline_summary, candidate['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "See if you can beat the bot. Try modifying the summary in the next cell and try to improve the quality of summary. Alternatively put a low quality summary in and see the responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "\n",
    "# - create the Anthropic Model\n",
    "bedrock_embeddings = BedrockEmbeddings(client=boto3_bedrock)\n",
    "\n",
    "hf_evaluator = load_evaluator(\"embedding_distance\",llm = textgen_llm, embeddings=bedrock_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the results\n",
    "Before we jump into the  comparison, we'll take a sidetrack on how embeddings work.  We'll do this by looking at a simple example, and seeing the embedding distance with some candidate examples. The important thing to keep in mind, is the embedding should represent the symantic meaning of a sentence.\n",
    "\n",
    "In the example, we'll take a simple sentence and try variations of the sentence, some with very similar meanings, and other with very different meanings, and view the results.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Baseline**: ***Cooper is a dog that likes to eat beef.***\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.035882</td>\n",
       "      <td>Cooper is a puppy that likes to eat beef.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.083690</td>\n",
       "      <td>Beef is what a dog named Cooper likes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.109997</td>\n",
       "      <td>Cooper is a dog that likes to eat steak.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.135489</td>\n",
       "      <td>Cooper is a dog that hates eating beef.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.184443</td>\n",
       "      <td>Cooper is a dog that likes to eat chicken.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.192230</td>\n",
       "      <td>Fido is a dog that likes to eat beef.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.194594</td>\n",
       "      <td>Cooper is a cat that likes to eat beef.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.228607</td>\n",
       "      <td>Spot is a dog that likes to eat beef.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.264782</td>\n",
       "      <td>Cooper is a man that likes to eat beef.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.351404</td>\n",
       "      <td>Cooper ist ein Hund, der gerne Rindfleisch frisst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.799773</td>\n",
       "      <td>A cooper is someone that makes barrels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.016293</td>\n",
       "      <td>Amazon Web Services provides on-demand cloud computing platforms and APIs pay-as-you-go basis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import HTML, Markdown\n",
    "\n",
    "def compare_embeddings(prediction, reference):\n",
    "    score = hf_evaluator.evaluate_strings(prediction=prediction, reference=reference)['score']\n",
    "    return {\"score\":score, \"text\":prediction}\n",
    "\n",
    "string1 = \"Cooper is a dog that likes to eat beef.\"\n",
    "\n",
    "comparison_strings = [\"Cooper is a puppy that likes to eat beef.\",\n",
    "                      \"Cooper is a man that likes to eat beef.\",\n",
    "                      \"Cooper is a cat that likes to eat beef.\",\n",
    "                      \"Cooper is a dog that likes to eat chicken.\",\n",
    "                      \"Cooper ist ein Hund, der gerne Rindfleisch frisst\",\n",
    "                      \"A cooper is someone that makes barrels\",\n",
    "                      \"Cooper is a dog that likes to eat steak.\",\n",
    "                      \"Beef is what a dog named Cooper likes.\",\n",
    "                      \"Fido is a dog that likes to eat beef.\",\n",
    "                      \"Spot is a dog that likes to eat beef.\",\n",
    "                      \"Cooper is a dog that hates eating beef.\",\n",
    "                      \"Amazon Web Services provides on-demand cloud computing platforms and APIs pay-as-you-go basis\"]\n",
    "results = []\n",
    "for comp in comparison_strings:\n",
    "    results.append(compare_embeddings(prediction=comp, reference=string1))\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "**Baseline**: ***{string1}***\n",
    "\"\"\"))\n",
    "display(HTML(pd.DataFrame.from_dict(results).sort_values(by=\"score\").to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret Embeddings Results\n",
    "The closer two strings are semantically, the closer they will be to zero. Notice in the example above, that cat is closer to dog from a string distance. But because the embeddings take into account the semantic context of the word, pupper will be closer than cat. Because cats and dogs are both animals, they are closer than man.\n",
    "\n",
    "Again, because filet mignon is a type of steak, the comparison to filet mignon will be closer in meaning than chicken.\n",
    "\n",
    "Note that the German translation scores relatively well, even though it is in a different language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>score</th>\n",
       "      <th>candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.185844</td>\n",
       "      <td>AI21 Labs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.227487</td>\n",
       "      <td>Amazon Titan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.465222</td>\n",
       "      <td>Anthropic Claude on 2017 Letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.040069</td>\n",
       "      <td>Unrelated Article on Honus Wagner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = [{\"score\": hf_evaluator.evaluate_strings(prediction=candidate['text'], reference=baseline_summary)['score'], \"candidate\": candidate['note']} for candidate in candidates]\n",
    "\n",
    "display(HTML(pd.DataFrame.from_dict(results).sort_values(by=\"score\").to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret the results\n",
    "You probably noticed that the results are returned quickly, since the model is only calculating the embeddings, then using the client to compare the embedding vectors. The closer the number is to zero, the more similar the documents are found to be. \n",
    "\n",
    "The tradeoff is that the embedding comparison doesn't tell you why the strings are different, or if one summary is better than another. However, if you have a set of ground truth examples, the embeddings can tell you symantically how close the response is to the ground truth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Review - Next Steps\n",
    "Play with the examples above, trying different variations on the summary and seeing how the comparison works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
